{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamadri/Transformers/blob/main/model_utils_and_training_drive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f49b63e5-0c97-470b-817e-0f82f14dfd8d",
      "metadata": {
        "id": "f49b63e5-0c97-470b-817e-0f82f14dfd8d"
      },
      "source": [
        "# Utils and Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a72566f-8da4-40a0-851d-54fe28fb7636",
      "metadata": {
        "id": "6a72566f-8da4-40a0-851d-54fe28fb7636"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03bcd3cb-50f6-4a83-9113-15a6f1f2ba28",
      "metadata": {
        "id": "03bcd3cb-50f6-4a83-9113-15a6f1f2ba28"
      },
      "source": [
        "### addAndNorm.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "df6ea7fd-ec7d-4c37-b5e8-73e663b1ec30",
      "metadata": {
        "id": "df6ea7fd-ec7d-4c37-b5e8-73e663b1ec30"
      },
      "outputs": [],
      "source": [
        "\"\"\"Residual connection.\"\"\"\n",
        "\n",
        "\n",
        "def addAndNorm(x, blockOutput, norm):\n",
        "    \"\"\"Residual connection.\"\"\"\n",
        "    return norm(x + blockOutput)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6176556f-9240-493a-93d9-8f3a0c9b42ef",
      "metadata": {
        "id": "6176556f-9240-493a-93d9-8f3a0c9b42ef"
      },
      "source": [
        "### PositionalEncoding.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d9923029-9788-4ce9-8518-2b21105d3929",
      "metadata": {
        "id": "d9923029-9788-4ce9-8518-2b21105d3929"
      },
      "outputs": [],
      "source": [
        "\"\"\"Positional Encoding.\"\"\"\n",
        "import math\n",
        "import torch\n",
        "\n",
        "\n",
        "def positionalEncoding(x, dim_model):\n",
        "    \"\"\"Positional Encoding.\"\"\"\n",
        "    def sineOrCosine(i):\n",
        "        \"\"\"sin(alpha+pi/2) = cos(alpha).\"\"\"\n",
        "        return math.pi/2*(i % 2 == 1)\n",
        "    values = [\n",
        "        [sineOrCosine(i) + pos/math.pow(10000, 2*(i//2)/dim_model) for\n",
        "         i in range(dim_model)]\n",
        "        for pos in range(x.shape[-2])  # seq_length\n",
        "    ]\n",
        "    return torch.sin(torch.tensor(values)).unsqueeze(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39d82e56-e9f2-4551-9461-6a16c6824a42",
      "metadata": {
        "id": "39d82e56-e9f2-4551-9461-6a16c6824a42"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WlgZBE6f5jIb",
        "outputId": "d8497bce-cc36-4de0-fc49-a65320776af7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "WlgZBE6f5jIb",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/Transformers/data"
      ],
      "metadata": {
        "id": "i9_mRnQ766eo",
        "outputId": "43ac3e26-f0a6-432a-bcc5-34d93c064226",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "i9_mRnQ766eo",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiny_shakespeare.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "199362f1-377e-4955-86c2-f775b520b012",
      "metadata": {
        "id": "199362f1-377e-4955-86c2-f775b520b012"
      },
      "outputs": [],
      "source": [
        "tiny_shakespeare = open('/content/drive/MyDrive/Transformers/data/tiny_shakespeare.txt',\n",
        "            'rb').read().decode(encoding='utf-8')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1106be76-87e9-405c-a431-8569ef02043a",
      "metadata": {
        "id": "1106be76-87e9-405c-a431-8569ef02043a"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9297b179-d38c-4cb9-a023-4f32a6d26367",
      "metadata": {
        "id": "9297b179-d38c-4cb9-a023-4f32a6d26367",
        "outputId": "af721954-87b3-4903-e889-53b6b59ed321",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LonelyDecoder(\n",
            "  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (embedding): Embedding(\n",
            "    (embedding): Linear(in_features=67, out_features=256, bias=True)\n",
            "  )\n",
            "  (multiheads1): ModuleList(\n",
            "    (0): MultiHeadAttention(\n",
            "      (WQs): ModuleList(\n",
            "        (0-3): 4 x Linear(in_features=256, out_features=64, bias=True)\n",
            "      )\n",
            "      (WKs): ModuleList(\n",
            "        (0-3): 4 x Linear(in_features=256, out_features=64, bias=True)\n",
            "      )\n",
            "      (WVs): ModuleList(\n",
            "        (0-3): 4 x Linear(in_features=256, out_features=64, bias=True)\n",
            "      )\n",
            "      (spda): ScaledDotProductAttention(\n",
            "        (softmax): Softmax(dim=-1)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (feedforwards): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (toLogit): Linear(in_features=256, out_features=67, bias=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    \"\"\"Main transformer block.\n",
        "\n",
        "    Inputs: - model_parameters: ordered dictionary of key-values describing the\n",
        "    layer parameters of the model:\n",
        "      - dim_model: dimension of the model.\n",
        "      - layers: dictionary of key-values describing specific layers\n",
        "        - <layer_name>: dictionary of parameters for the specific multi-head\n",
        "          layer\n",
        "          - attention: dictionary of parameters for the specific attention\n",
        "            function\n",
        "            - dim_key: dimension of the key and query.\n",
        "            - dim_value: dimension of the value.\n",
        "          - nb_head: number of heads.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_parameters):\n",
        "        \"\"\"Initialize parameters.\"\"\"\n",
        "        super().__init__()\n",
        "        self.dim_model = model_parameters[\"dim_model\"]\n",
        "        self.encoder = Encoder(model_parameters[\"encoder\"])\n",
        "        self.decoder = Decoder(model_parameters[\"decoder\"])\n",
        "        self.embedding = Embedding(model_parameters)\n",
        "        self.toProba = nn.Sequential(\n",
        "            nn.Linear(self.dim_model,\n",
        "                      model_parameters[\"vocabulary_size\"]),\n",
        "            nn.Softmax()\n",
        "        )\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x, lastOutput):\n",
        "        \"\"\"Apply a step forward.\"\"\"\n",
        "        encoderInput = self.embedding(x) + positionalEncoding(\n",
        "            x, self.dim_model)\n",
        "        decoderInput = self.embedding(lastOutput) + positionalEncoding(\n",
        "            lastOutput, self.dim_model)\n",
        "        encoderInput = self.dropout(encoderInput)\n",
        "        decoderInput = self.dropout(decoderInput)\n",
        "        encoderOutput = self.encoder(encoderInput)\n",
        "        decoderOutput = self.decoder(decoderInput, encoderOutput)\n",
        "        lastOutput = self.toProba(decoderOutput)\n",
        "        return lastOutput\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"Encoder.\"\"\"\n",
        "\n",
        "    def __init__(self, encoderConfig):\n",
        "        \"\"\"Initialize.\"\"\"\n",
        "        super().__init__()\n",
        "        self.nb_layers = encoderConfig[\"nb_layers\"]\n",
        "        self.dim_model = encoderConfig[\"dim_model\"]\n",
        "        self.dim_feedforward = encoderConfig[\"feedforward\"][\"dim_feedforward\"]\n",
        "        self.norm = nn.LayerNorm(normalized_shape=self.dim_model,\n",
        "                                 elementwise_affine=True, bias=True)\n",
        "        self.multiheads = [MultiHeadAttention(encoderConfig[\"multihead\"],\n",
        "                                              masked=False)\n",
        "                           for i in range(self.nb_layers)]\n",
        "        self.feedforwards = [nn.Sequential(nn.Linear(self.dim_model,\n",
        "                                                     self.dim_feedforward),\n",
        "                                           nn.ReLU(),\n",
        "                                           nn.Linear(self.dim_feedforward,\n",
        "                                                     self.dim_model))\n",
        "                             for i in range(self.nb_layers)]\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward.\"\"\"\n",
        "        for i in range(self.nb_layers):\n",
        "            h1 = addAndNorm(x, self.dropout(self.multiheads[i](x, x,\n",
        "                                                               x)),\n",
        "                            self.norm)\n",
        "            x = addAndNorm(h1, self.dropout(self.feedforwards[i](h1)),\n",
        "                           self.norm)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"Decoder.\"\"\"\n",
        "\n",
        "    def __init__(self, decoderConfig):\n",
        "        \"\"\"Initialize.\"\"\"\n",
        "        super().__init__()\n",
        "        self.dim_model = decoderConfig[\"dim_model\"]\n",
        "        self.norm = nn.LayerNorm(normalized_shape=self.dim_model)\n",
        "        self.dim_feedforward = decoderConfig[\"feedforward\"][\"dim_feedforward\"]\n",
        "        self.nb_layers = decoderConfig[\"nb_layers\"]\n",
        "        self.layer = []\n",
        "        self.multiheads1 = [MultiHeadAttention(decoderConfig[\"multihead\"],\n",
        "                                               masked=True)\n",
        "                            for i in range(self.nb_layers)]\n",
        "        self.multiheads2 = [MultiHeadAttention(decoderConfig[\"multihead\"],\n",
        "                                               masked=False)\n",
        "                            for i in range(self.nb_layers)]\n",
        "        self.feedforwards = [nn.Sequential(nn.Linear(self.dim_model,\n",
        "                                                     self.dim_feedforward),\n",
        "                                           nn.ReLU(),\n",
        "                                           nn.Linear(self.dim_feedforward,\n",
        "                                                     self.dim_model))\n",
        "                             for i in range(self.nb_layers)]\n",
        "\n",
        "    def forward(self, decoderInput, encoderOutput):\n",
        "        \"\"\"Forward.\"\"\"\n",
        "        for i in range(self.nb_layers):\n",
        "            h1 = addAndNorm(decoderInput,\n",
        "                            self.multiheads1[i](decoderInput,\n",
        "                                                decoderInput,\n",
        "                                                decoderInput),\n",
        "                            self.norm)\n",
        "            h2 = addAndNorm(h1,\n",
        "                            self.multiheads2[i](h1,\n",
        "                                                encoderOutput,\n",
        "                                                encoderOutput),\n",
        "                            self.norm)\n",
        "            lastOutput = addAndNorm(h2,\n",
        "                                    self.feedforwards[i](h2),\n",
        "                                    self.norm)\n",
        "        return lastOutput\n",
        "\n",
        "\n",
        "class LonelyDecoder(nn.Module):\n",
        "    \"\"\"A lonely decoder.\"\"\"\n",
        "\n",
        "    def __init__(self, model_parameters):\n",
        "        \"\"\"Initialize.\"\"\"\n",
        "        super().__init__()\n",
        "        self.decoderConfig = model_parameters[\"decoder\"]\n",
        "        self.dim_model = self.decoderConfig[\"dim_model\"]\n",
        "        self.norm = nn.LayerNorm(normalized_shape=self.dim_model)\n",
        "        self.dim_feedforward = self.decoderConfig[\"feedforward\"][\"dim_feedforward\"]\n",
        "        self.nb_layers = self.decoderConfig[\"nb_layers\"]\n",
        "        self.embedding = Embedding(model_parameters)\n",
        "        self.multiheads1 = nn.ModuleList([MultiHeadAttention(self.decoderConfig[\"multihead\"],\n",
        "                                               masked=True)\n",
        "                            for i in range(self.nb_layers)])\n",
        "        #self.multiheads2 = nn.ModuleList([MultiHeadAttention(self.decoderConfig[\"multihead\"],\n",
        "        #                                       masked=False)\n",
        "        #                    for i in range(self.nb_layers)])\n",
        "        self.feedforwards = nn.ModuleList([nn.Sequential(nn.Linear(self.dim_model,\n",
        "                                                     self.dim_feedforward),\n",
        "                                           nn.ReLU(),\n",
        "                                           nn.Linear(self.dim_feedforward,\n",
        "                                                     self.dim_model))\n",
        "                             for i in range(self.nb_layers)])\n",
        "        self.toLogit = nn.Linear(self.dim_model,\n",
        "                                 model_parameters[\"vocabulary_size\"])\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward.\"\"\"\n",
        "        x = self.embedding(x) + positionalEncoding(\n",
        "            x, self.dim_model)\n",
        "        x = self.dropout(x)\n",
        "        for i in range(self.nb_layers):\n",
        "            h1 = addAndNorm(x,\n",
        "                            self.dropout(self.multiheads1[i](x, x, x)),\n",
        "                            self.norm)\n",
        "            #h2 = addAndNorm(h1,\n",
        "            #                self.dropout(self.multiheads2[i](h1, h1, h1)),\n",
        "            #                self.norm)\n",
        "            layerOutput = addAndNorm(h1,\n",
        "                                     self.dropout(self.feedforwards[i](h1)),\n",
        "                                     self.norm)\n",
        "        finalOutput = self.toLogit(layerOutput)\n",
        "        return finalOutput\n",
        "\n",
        "\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    \"\"\"Scaled Dot-Product Attention.\"\"\"\n",
        "\n",
        "    def __init__(self, dim_model, masked=False):\n",
        "        \"\"\"Initialize.\n",
        "\n",
        "        Inputs:\n",
        "        - dim_model: model dimension\n",
        "        - masked: prevents tokens to attend to the following ones.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.dim_model = dim_model\n",
        "        self.masked = masked\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, Q, K, V):\n",
        "        \"\"\"Forward.\n",
        "\n",
        "        Inputs:\n",
        "        - Q: query\n",
        "        - K: key\n",
        "        - V: value\n",
        "        \"\"\"\n",
        "        matmul_0 = torch.matmul(Q, K.transpose(-2, -1))\n",
        "        scaled = torch.divide(matmul_0, torch.Tensor([self.dim_model]))\n",
        "        if self.masked:\n",
        "            mask = torch.ones(scaled.shape)\n",
        "            mask = mask - torch.tril(mask)*mask\n",
        "            mask = torch.where(mask == 1, float('-inf'), 0)\n",
        "            scaled = scaled + mask\n",
        "        softmaxed = self.softmax(scaled)\n",
        "        sdpa = torch.matmul(softmaxed, V)\n",
        "        return sdpa\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"Multi-Head Attention.\n",
        "\n",
        "    Inputs:\n",
        "    - multi_head_config: dictionary\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, multi_head_config, masked=False):\n",
        "        \"\"\"Initialize multi-head.\"\"\"\n",
        "        super().__init__()\n",
        "        self.dim_key = multi_head_config[\"attention\"][\"dim_key\"]\n",
        "        self.dim_value = multi_head_config[\"attention\"][\"dim_value\"]\n",
        "        self.nb_heads = multi_head_config[\"nb_heads\"]\n",
        "        self.dim_model = self.dim_key * self.nb_heads\n",
        "\n",
        "        self.WQs = nn.ModuleList([nn.Linear(self.dim_model, self.dim_key)\n",
        "                    for i in range(self.nb_heads)])\n",
        "        self.WKs = nn.ModuleList([nn.Linear(self.dim_model, self.dim_key)\n",
        "                    for i in range(self.nb_heads)])\n",
        "        self.WVs = nn.ModuleList([nn.Linear(self.dim_model, self.dim_value)\n",
        "                    for i in range(self.nb_heads)])\n",
        "        self.spda = ScaledDotProductAttention(self.dim_model, masked)\n",
        "\n",
        "    def forward(self, Q, K, V):\n",
        "        \"\"\"One step of the multi-head block.\"\"\"\n",
        "        heads = [self.spda(self.WQs[i](Q),\n",
        "                           self.WKs[i](K),\n",
        "                           self.WVs[i](V))\n",
        "                 for i in range(self.nb_heads)]\n",
        "        return torch.cat([head for head in heads], -1)\n",
        "\n",
        "\n",
        "class Embedding(nn.Module):\n",
        "    \"\"\"Embedding.\"\"\"\n",
        "\n",
        "    def __init__(self, model_parameters):\n",
        "        \"\"\"Initialize embedding.\"\"\"\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Linear(model_parameters[\"vocabulary_size\"],\n",
        "                                   model_parameters[\"dim_model\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward step.\"\"\"\n",
        "        return self.embedding(x)\n",
        "\n",
        "model_parameters = {\n",
        "    \"dim_model\": 256,\n",
        "    \"vocabulary_size\": 67,\n",
        "    \"batch_size\": 64,\n",
        "    \"encoder\": {\n",
        "        \"nb_layers\": 1,\n",
        "        \"dim_model\": 256,\n",
        "        \"multihead\": {\n",
        "            \"attention\": {\n",
        "                \"dim_model\": 256,\n",
        "                \"dim_key\": 128,\n",
        "                \"dim_value\": 128\n",
        "                },\n",
        "            \"nb_heads\": 2\n",
        "            },\n",
        "        \"feedforward\": {\n",
        "            \"dim_feedforward\": 256\n",
        "            }\n",
        "        },\n",
        "    \"decoder\": {\n",
        "        \"nb_layers\": 1,\n",
        "        \"vocabulary_size\": 67,\n",
        "        \"dim_model\": 256,\n",
        "        \"multihead\": {\n",
        "            \"attention\": {\n",
        "                \"dim_model\": 256,\n",
        "                \"dim_key\": 64,\n",
        "                \"dim_value\": 64,\n",
        "            },\n",
        "            \"nb_heads\": 4\n",
        "        },\n",
        "        \"feedforward\": {\n",
        "            \"dim_feedforward\": 256\n",
        "        }\n",
        "    }\n",
        "}\n",
        "decoder = LonelyDecoder(model_parameters)\n",
        "print(decoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ab4af4e-d6f7-4380-b6dd-bc270c76644d",
      "metadata": {
        "id": "2ab4af4e-d6f7-4380-b6dd-bc270c76644d"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1ae36615-9abe-48c3-851b-e1d88cc4ed79",
      "metadata": {
        "id": "1ae36615-9abe-48c3-851b-e1d88cc4ed79",
        "outputId": "4ad315e3-15ac-4acf-8558-fa34b263d612",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "67 unique characters\n",
            "char2idx\n",
            "{'\\n': 0, ' ': 1, '!': 2, '#': 3, '$': 4, '&': 5, \"'\": 6, ',': 7, '-': 8, '.': 9, '3': 10, ':': 11, ';': 12, '?': 13, '@': 14, 'A': 15, 'B': 16, 'C': 17, 'D': 18, 'E': 19, 'F': 20, 'G': 21, 'H': 22, 'I': 23, 'J': 24, 'K': 25, 'L': 26, 'M': 27, 'N': 28, 'O': 29, 'P': 30, 'Q': 31, 'R': 32, 'S': 33, 'T': 34, 'U': 35, 'V': 36, 'W': 37, 'X': 38, 'Y': 39, 'Z': 40, 'a': 41, 'b': 42, 'c': 43, 'd': 44, 'e': 45, 'f': 46, 'g': 47, 'h': 48, 'i': 49, 'j': 50, 'k': 51, 'l': 52, 'm': 53, 'n': 54, 'o': 55, 'p': 56, 'q': 57, 'r': 58, 's': 59, 't': 60, 'u': 61, 'v': 62, 'w': 63, 'x': 64, 'y': 65, 'z': 66}\n",
            "idx2char\n",
            "['\\n' ' ' '!' '#' '$' '&' \"'\" ',' '-' '.' '3' ':' ';' '?' '@' 'A' 'B' 'C'\n",
            " 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U'\n",
            " 'V' 'W' 'X' 'Y' 'Z' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm'\n",
            " 'n' 'o' 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n",
            "text_as_int\n",
            "[20 49 58 ... 47  9  0]\n",
            "'First Citizen' ---- characters mapped to int ---- >[20 49 58 59 60  1 17 49 60 49 66 45 54]\n",
            "tensor([20, 49, 58,  ..., 47,  9,  0])\n",
            "There are 123933 chunks of 8 characters available for the\n",
            "network training.\n",
            "one_hot_examples shape: torch.Size([123932, 8, 67])\n",
            "First Ci\n",
            "targets shape: torch.Size([123932, 8])\n",
            "irst Cit\n",
            "one_hot_examples[0].shape: torch.Size([8, 67])\n",
            "targets[0].shape: torch.Size([8])\n",
            "LonelyDecoder(\n",
            "  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  (embedding): Embedding(\n",
            "    (embedding): Linear(in_features=67, out_features=512, bias=True)\n",
            "  )\n",
            "  (multiheads1): ModuleList(\n",
            "    (0-1): 2 x MultiHeadAttention(\n",
            "      (WQs): ModuleList(\n",
            "        (0-7): 8 x Linear(in_features=512, out_features=64, bias=True)\n",
            "      )\n",
            "      (WKs): ModuleList(\n",
            "        (0-7): 8 x Linear(in_features=512, out_features=64, bias=True)\n",
            "      )\n",
            "      (WVs): ModuleList(\n",
            "        (0-7): 8 x Linear(in_features=512, out_features=64, bias=True)\n",
            "      )\n",
            "      (spda): ScaledDotProductAttention(\n",
            "        (softmax): Softmax(dim=-1)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (feedforwards): ModuleList(\n",
            "    (0-1): 2 x Sequential(\n",
            "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (toLogit): Linear(in_features=512, out_features=67, bias=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 4.0808e-01, -1.8708e-01,  7.3544e-02,  ..., -4.4160e-01,\n",
              "          -1.7063e+00,  7.4681e-01],\n",
              "         [ 1.5869e-01,  1.7166e-01,  1.2130e-01,  ..., -4.1554e-01,\n",
              "          -1.3952e+00,  1.8097e-01],\n",
              "         [ 2.6047e-01,  1.3284e-02, -2.1905e-01,  ..., -6.9609e-01,\n",
              "          -1.2904e+00,  1.5391e-01],\n",
              "         ...,\n",
              "         [ 1.3779e-02, -4.5717e-01, -4.6445e-01,  ..., -3.1142e-01,\n",
              "          -1.4821e+00,  1.2648e-01],\n",
              "         [-5.6810e-02, -2.2508e-01, -4.0563e-01,  ..., -4.6117e-01,\n",
              "          -1.5169e+00,  7.8773e-01],\n",
              "         [ 3.3284e-01, -5.1325e-01, -3.8192e-01,  ...,  6.2056e-02,\n",
              "          -9.1226e-01,  1.0539e+00]],\n",
              "\n",
              "        [[ 1.9414e-01,  7.1182e-01,  3.8132e-01,  ..., -3.4795e-02,\n",
              "          -1.8021e+00, -4.9885e-02],\n",
              "         [ 5.2441e-01,  5.8812e-01, -1.0090e-01,  ..., -2.5126e-01,\n",
              "          -1.2931e+00,  6.7215e-01],\n",
              "         [-1.6341e-01,  2.8201e-01,  4.9299e-01,  ..., -1.0398e+00,\n",
              "          -1.7562e+00,  4.8206e-01],\n",
              "         ...,\n",
              "         [-8.4307e-02, -6.2810e-01, -1.5715e-01,  ..., -6.6803e-01,\n",
              "          -1.3062e+00,  2.2435e-01],\n",
              "         [ 2.3475e-01, -5.2738e-01, -4.6562e-01,  ..., -2.7622e-01,\n",
              "          -1.2066e+00,  9.7917e-01],\n",
              "         [ 1.4349e-01, -3.2436e-01, -6.3385e-01,  ..., -1.7656e-01,\n",
              "          -1.4232e+00,  1.0835e+00]],\n",
              "\n",
              "        [[ 4.4548e-01,  9.5842e-01,  2.9100e-01,  ...,  2.7541e-01,\n",
              "          -1.5190e+00,  7.2568e-02],\n",
              "         [ 4.7834e-01,  5.0304e-01,  4.1187e-01,  ...,  8.9730e-02,\n",
              "          -1.5893e+00,  4.5662e-01],\n",
              "         [ 2.4271e-02,  2.1489e-02, -5.8859e-02,  ..., -2.4789e-01,\n",
              "          -1.4627e+00,  1.3871e-01],\n",
              "         ...,\n",
              "         [-1.9674e-01, -4.7325e-01, -5.0803e-01,  ..., -5.9856e-01,\n",
              "          -1.5319e+00,  6.5119e-01],\n",
              "         [ 7.1099e-01, -2.9721e-01, -5.4814e-01,  ..., -2.3390e-01,\n",
              "          -7.7487e-01,  1.0884e+00],\n",
              "         [-7.6551e-02, -2.9230e-01, -6.1398e-01,  ..., -2.9197e-01,\n",
              "          -1.4706e+00,  1.0538e+00]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 9.8148e-02,  7.1089e-01,  1.6474e-01,  ..., -3.1310e-01,\n",
              "          -1.1080e+00,  5.4457e-01],\n",
              "         [-1.5309e-02,  1.0437e-01,  2.4646e-01,  ..., -2.6427e-03,\n",
              "          -1.4890e+00,  6.0038e-01],\n",
              "         [ 1.2128e-01,  8.7666e-02,  3.0538e-01,  ..., -1.3588e-01,\n",
              "          -1.4814e+00,  1.2863e-01],\n",
              "         ...,\n",
              "         [ 8.9412e-02, -3.5734e-01, -2.2812e-01,  ..., -8.8513e-05,\n",
              "          -1.4751e+00,  2.2449e-01],\n",
              "         [ 7.6136e-01, -4.8140e-01, -6.4202e-01,  ...,  1.4632e-01,\n",
              "          -1.7686e+00,  9.8881e-01],\n",
              "         [ 3.6139e-01, -4.2045e-01, -2.5560e-01,  ..., -2.6210e-01,\n",
              "          -1.3497e+00,  1.1078e+00]],\n",
              "\n",
              "        [[ 6.5518e-01,  6.7478e-01, -3.0026e-02,  ..., -7.0531e-02,\n",
              "          -1.8595e+00,  4.8230e-01],\n",
              "         [ 2.5127e-03,  6.2793e-01,  7.5807e-01,  ..., -2.1393e-02,\n",
              "          -2.0110e+00,  3.8185e-01],\n",
              "         [ 1.7906e-01,  3.8574e-01,  1.1875e-01,  ...,  3.0958e-01,\n",
              "          -2.0921e+00,  2.6151e-01],\n",
              "         ...,\n",
              "         [-3.5746e-01, -4.5997e-01, -4.0787e-01,  ..., -3.4082e-01,\n",
              "          -1.8120e+00,  4.3857e-01],\n",
              "         [ 2.7567e-01, -1.9216e-01, -1.2698e-01,  ..., -1.1996e-01,\n",
              "          -1.4758e+00,  7.9790e-01],\n",
              "         [-1.9580e-02, -3.3880e-01, -3.5043e-01,  ...,  9.5962e-02,\n",
              "          -1.0940e+00,  8.4254e-01]],\n",
              "\n",
              "        [[ 6.7669e-02, -2.4262e-01,  5.8178e-01,  ..., -2.4201e-01,\n",
              "          -1.3304e+00, -7.1479e-01],\n",
              "         [-3.7589e-03,  3.9680e-01,  2.5235e-01,  ..., -3.0677e-01,\n",
              "          -1.3413e+00,  2.2933e-01],\n",
              "         [ 3.4199e-02, -9.0611e-02,  7.5217e-02,  ..., -5.2339e-01,\n",
              "          -1.7080e+00, -1.5423e-01],\n",
              "         ...,\n",
              "         [-1.3173e-01,  9.2644e-02, -2.1156e-01,  ..., -6.1600e-01,\n",
              "          -1.6282e+00,  6.3936e-01],\n",
              "         [ 9.3753e-02, -2.6731e-01, -2.5577e-01,  ..., -3.5968e-01,\n",
              "          -1.6438e+00,  1.0171e+00],\n",
              "         [ 5.3205e-01, -5.5594e-01, -6.2010e-01,  ..., -6.0493e-01,\n",
              "          -1.5296e+00,  8.2542e-01]]], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# \"\"\"Training.\"\"\"\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "# # import Transformers.model.transformer.Transformer\n",
        "\n",
        "text = tiny_shakespeare\n",
        "print('Length of text: {} characters'.format(len(text)))\n",
        "print(text[:250])\n",
        "\n",
        "# unique characters in the file\n",
        "vocab = sorted(set(text+\"@\"+\"#\")) # @ will be the initial character\n",
        "                                  # and # the final character. They\n",
        "                                  # are not in the text.\n",
        "print('{} unique characters'.format(len(vocab)))\n",
        "\n",
        "# Lookup tables\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])\n",
        "print(\"char2idx\")\n",
        "print(char2idx)\n",
        "print(\"idx2char\")\n",
        "print(idx2char)\n",
        "print(\"text_as_int\")\n",
        "print(text_as_int)\n",
        "print ('{} ---- characters mapped to int ---- >{}'.format(repr(text[:13]), text_as_int[:13]))\n",
        "\n",
        "# Create training examples:\n",
        "seq_length = 8\n",
        "examples_per_epoch = len(text)//(seq_length)\n",
        "\n",
        "int_text_tensor = torch.tensor(text_as_int)\n",
        "chunks = torch.chunk(int_text_tensor, examples_per_epoch, 0)\n",
        "print(int_text_tensor)\n",
        "\n",
        "examples = [chunk[:-1] for chunk in chunks]\n",
        "targets = [chunk[1:] for chunk in chunks]\n",
        "print(f\"\"\"There are {len(examples)} chunks of {seq_length} characters available for the\n",
        "network training.\"\"\")\n",
        "\n",
        "\n",
        "\n",
        "model_parameters = {\n",
        "    \"dim_model\": 512,\n",
        "    \"vocabulary_size\": 67,\n",
        "    \"batch_size\": 64,\n",
        "    \"encoder\": {\n",
        "        \"nb_layers\": 1,\n",
        "        \"dim_model\": 256,\n",
        "        \"multihead\": {\n",
        "            \"attention\": {\n",
        "                \"dim_model\": 256,\n",
        "                \"dim_key\": 128,\n",
        "                \"dim_value\": 128\n",
        "                },\n",
        "            \"nb_heads\": 2\n",
        "            },\n",
        "        \"feedforward\": {\n",
        "            \"dim_feedforward\": 256\n",
        "            }\n",
        "        },\n",
        "    \"decoder\": {\n",
        "        \"nb_layers\": 2,\n",
        "        \"vocabulary_size\": 67,\n",
        "        \"dim_model\": 512,\n",
        "        \"multihead\": {\n",
        "            \"attention\": {\n",
        "                \"dim_model\": 512,\n",
        "                \"dim_key\": 64,\n",
        "                \"dim_value\": 64,\n",
        "            },\n",
        "            \"nb_heads\": 8\n",
        "        },\n",
        "        \"feedforward\": {\n",
        "            \"dim_feedforward\": 512\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# transformer = Transformer(model_parameters)\n",
        "# x = torch.randn(10, 128)\n",
        "# lastOutput = torch.randn(3, 128)\n",
        "# transformer(x, lastOutput)\n",
        "\n",
        "decoder = LonelyDecoder(model_parameters)\n",
        "x = torch.randn(10, model_parameters[\"vocabulary_size\"])\n",
        "lastOutput = torch.randn(3, model_parameters[\"vocabulary_size\"])\n",
        "#decoder(x)\n",
        "\n",
        "\n",
        "one_hot_examples = F.one_hot(torch.stack(examples[:-1]).long(),\n",
        "                             model_parameters[\"vocabulary_size\"]).float()\n",
        "targets = torch.stack(targets[:-1]).long()\n",
        "\n",
        "print(f\"one_hot_examples shape: {one_hot_examples.shape}\")\n",
        "print(''.join([idx2char[i] for i in torch.max(one_hot_examples[0], dim=1)[1].tolist()]))\n",
        "print(f\"targets shape: {targets.shape}\")\n",
        "print(''.join([idx2char[i] for i in targets[0]]))\n",
        "print(f\"one_hot_examples[0].shape: {one_hot_examples[0].shape}\")\n",
        "print(f\"targets[0].shape: {targets[0].shape}\")\n",
        "#decoder(one_hot_examples[0])\n",
        "one_hot_examples[0]\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "#loss = loss_fn(decoder(one_hot_examples[0]), one_hot_targets[0])\n",
        "#loss.backward()\n",
        "optimizer = torch.optim.Adam(decoder.parameters(), lr=1e-3, betas=(0.9, 0.98))\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class customDataset(Dataset):\n",
        "    def __init__(self, data, target):\n",
        "        self.data  = data\n",
        "        self.target = target\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.target[idx]\n",
        "\n",
        "# dataset = customDataset(data, target)\n",
        "dataset = customDataset(one_hot_examples, targets)\n",
        "train_dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "def train_loop(dataloader, model, loss_fn, optimizer, t):\n",
        "    \"\"\"Train loop. Taken from pytorch tutorial.\"\"\"\n",
        "    size = len(dataloader.dataset)\n",
        "    # Set the model to training mode - important for batch\n",
        "    # normalization and dropout layers Unnecessary in this situation\n",
        "    # but added for best practices\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss =  loss_fn(pred.transpose(1,2), y) # loss_fn(pred.transpose(1,2)[:,:,-1], y[:,-1])\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                print(f\"{name}: {param.data}\")\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * 64 + len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "            print(\"Input\")\n",
        "            print(''.join([idx2char[i] for i in torch.max(X[0], dim=1)[1].tolist()]))\n",
        "            print(\"Target\")\n",
        "            print(''.join([idx2char[i] for i in y[0]]))\n",
        "            print(\"Prediction\")\n",
        "            print(''.join([idx2char[i] for i in torch.max(pred[0], dim=1)[1].tolist()]))\n",
        "        torch.save({\n",
        "            'epoch': t+1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, f\"model_epoch{t}.pt\")\n",
        "\n",
        "def run_n_epochs(epochs, dataloader, model, loss_fn, optimizer):\n",
        "    for t in range(epochs):\n",
        "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "        train_loop(dataloader, model, loss_fn, optimizer, t)\n",
        "print(decoder)\n",
        "decoder(next(iter(train_dataloader))[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train loop\")\n",
        "def train_loop(dataloader, model, loss_fn, optimizer, t):\n",
        "    \"\"\"Train loop. Taken from pytorch tutorial.\"\"\"\n",
        "    size = len(dataloader.dataset)\n",
        "    # Set the model to training mode - important for batch\n",
        "    # normalization and dropout layers Unnecessary in this situation\n",
        "    # but added for best practices\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss =  loss_fn(pred.transpose(1,2), y) # loss_fn(pred.transpose(1,2)[:,:,-1], y[:,-1])\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * 64 + len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "            print(\"Input\")\n",
        "            print(''.join([idx2char[i] for i in torch.max(X[0], dim=1)[1].tolist()]))\n",
        "            print(\"Target\")\n",
        "            print(''.join([idx2char[i] for i in y[0]]))\n",
        "            print(\"Prediction\")\n",
        "            print(''.join([idx2char[i] for i in torch.max(pred[0], dim=1)[1].tolist()]))\n",
        "        torch.save({\n",
        "            'epoch': t+1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, f\"model_epoch{t}.pt\")\n",
        "def run_n_epochs(epochs, dataloader, model, loss_fn, optimizer):\n",
        "    for t in range(epochs):\n",
        "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "        train_loop(dataloader, model, loss_fn, optimizer, t)\n",
        "\n",
        "run_n_epochs(10, train_dataloader, decoder, loss_fn, optimizer)"
      ],
      "metadata": {
        "id": "i7mbxlZQ6bTa",
        "outputId": "803d0d5d-3692-4245-8c3a-f46c7afd11a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "i7mbxlZQ6bTa",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loop\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 4.440360  [   64/123932]\n",
            "Input\n",
            "hath som\n",
            "Target\n",
            "ath some\n",
            "Prediction\n",
            "k&@uBuTu\n",
            "loss: 2.641532  [ 6464/123932]\n",
            "Input\n",
            "I shall.\n",
            "Target\n",
            " shall. \n",
            "Prediction\n",
            " aoen  \n",
            "\n",
            "loss: 2.488205  [12864/123932]\n",
            "Input\n",
            "eorge!'\n",
            "\n",
            "Target\n",
            "orge!'\n",
            "\n",
            "\n",
            "Prediction\n",
            " r    dT\n",
            "loss: 2.387561  [19264/123932]\n",
            "Input\n",
            " dream t\n",
            "Target\n",
            "dream th\n",
            "Prediction\n",
            "tio n ah\n",
            "loss: 2.427102  [25664/123932]\n",
            "Input\n",
            "daughter\n",
            "Target\n",
            "aughter \n",
            "Prediction\n",
            " n      \n",
            "loss: 2.306042  [32064/123932]\n",
            "Input\n",
            " done, m\n",
            "Target\n",
            "done, my\n",
            "Prediction\n",
            "teu   ta\n",
            "loss: 2.319676  [38464/123932]\n",
            "Input\n",
            "ent befo\n",
            "Target\n",
            "nt befor\n",
            "Prediction\n",
            "   tenor\n",
            "loss: 2.382967  [44864/123932]\n",
            "Input\n",
            "mpathy,\n",
            "\n",
            "Target\n",
            "pathy,\n",
            "T\n",
            "Prediction\n",
            "eet e  T\n",
            "loss: 2.289113  [51264/123932]\n",
            "Input\n",
            " both yo\n",
            "Target\n",
            "both you\n",
            "Prediction\n",
            "terh tou\n",
            "loss: 2.163213  [57664/123932]\n",
            "Input\n",
            "gland!\n",
            "I\n",
            "Target\n",
            "land!\n",
            "I \n",
            "Prediction\n",
            "hend \n",
            "A \n",
            "loss: 2.241823  [64064/123932]\n",
            "Input\n",
            " in the \n",
            "Target\n",
            "in the f\n",
            "Prediction\n",
            "ts toe t\n",
            "loss: 2.256208  [70464/123932]\n",
            "Input\n",
            "atient? \n",
            "Target\n",
            "tient? a\n",
            "Prediction\n",
            "nhn t \n",
            "I\n",
            "loss: 2.121683  [76864/123932]\n",
            "Input\n",
            " Earl of\n",
            "Target\n",
            "Earl of \n",
            "Prediction\n",
            "tll  tf \n",
            "loss: 1.983875  [83264/123932]\n",
            "Input\n",
            "d speed \n",
            "Target\n",
            " speed a\n",
            "Prediction\n",
            " toe   t\n",
            "loss: 2.067958  [89664/123932]\n",
            "Input\n",
            "ve it he\n",
            "Target\n",
            "e it her\n",
            "Prediction\n",
            "e tn ter\n",
            "loss: 2.130250  [96064/123932]\n",
            "Input\n",
            "e in col\n",
            "Target\n",
            " in cold\n",
            "Prediction\n",
            " tn tomd\n",
            "loss: 2.149780  [102464/123932]\n",
            "Input\n",
            "r ope he\n",
            "Target\n",
            " ope her\n",
            "Prediction\n",
            " tfe te \n",
            "loss: 2.003837  [108864/123932]\n",
            "Input\n",
            "ry king \n",
            "Target\n",
            "y king o\n",
            "Prediction\n",
            "  ting t\n",
            "loss: 2.172671  [115264/123932]\n",
            "Input\n",
            "your que\n",
            "Target\n",
            "our quee\n",
            "Prediction\n",
            " u  tuee\n",
            "loss: 2.145478  [121664/123932]\n",
            "Input\n",
            " of this\n",
            "Target\n",
            "of this \n",
            "Prediction\n",
            "tf thes \n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.066151  [   64/123932]\n",
            "Input\n",
            "ntents t\n",
            "Target\n",
            "tents th\n",
            "Prediction\n",
            "d r   th\n",
            "loss: 2.037689  [ 6464/123932]\n",
            "Input\n",
            " Cliffor\n",
            "Target\n",
            "Clifford\n",
            "Prediction\n",
            "tooveere\n",
            "loss: 2.092850  [12864/123932]\n",
            "Input\n",
            " be so f\n",
            "Target\n",
            "be so fi\n",
            "Prediction\n",
            "te thmso\n",
            "loss: 1.929669  [19264/123932]\n",
            "Input\n",
            "de her f\n",
            "Target\n",
            "e her fa\n",
            "Prediction\n",
            " rtireto\n",
            "loss: 2.058861  [25664/123932]\n",
            "Input\n",
            "mselves\n",
            "\n",
            "Target\n",
            "selves\n",
            "D\n",
            "Prediction\n",
            "e  fe  A\n",
            "loss: 1.955132  [32064/123932]\n",
            "Input\n",
            "CORIOLAN\n",
            "Target\n",
            "ORIOLANU\n",
            "Prediction\n",
            "ERIANANU\n",
            "loss: 1.945058  [38464/123932]\n",
            "Input\n",
            "r had,\n",
            "T\n",
            "Target\n",
            " had,\n",
            "Th\n",
            "Prediction\n",
            " tev  Th\n",
            "loss: 1.898637  [44864/123932]\n",
            "Input\n",
            "cle, do \n",
            "Target\n",
            "le, do y\n",
            "Prediction\n",
            "ee  te t\n",
            "loss: 2.015373  [51264/123932]\n",
            "Input\n",
            " am none\n",
            "Target\n",
            "am none \n",
            "Prediction\n",
            "tn tote \n",
            "loss: 2.052401  [57664/123932]\n",
            "Input\n",
            "rst Citi\n",
            "Target\n",
            "st Citiz\n",
            "Prediction\n",
            "   totho\n",
            "loss: 1.908512  [64064/123932]\n",
            "Input\n",
            "e is gon\n",
            "Target\n",
            " is gone\n",
            "Prediction\n",
            " tn trog\n",
            "loss: 2.040678  [70464/123932]\n",
            "Input\n",
            "that are\n",
            "Target\n",
            "hat are \n",
            "Prediction\n",
            "het tne \n",
            "loss: 1.950155  [76864/123932]\n",
            "Input\n",
            " boy\n",
            "Sho\n",
            "Target\n",
            "boy\n",
            "Shou\n",
            "Prediction\n",
            "teuaAoeu\n",
            "loss: 2.063887  [83264/123932]\n",
            "Input\n",
            "herly,\n",
            "E\n",
            "Target\n",
            "erly,\n",
            "Er\n",
            "Prediction\n",
            "e  y  T \n",
            "loss: 2.000589  [89664/123932]\n",
            "Input\n",
            "nator:\n",
            "A\n",
            "Target\n",
            "ator:\n",
            "Am\n",
            "Prediction\n",
            " mer \n",
            "An\n",
            "loss: 2.006274  [96064/123932]\n",
            "Input\n",
            " Paulina\n",
            "Target\n",
            "Paulina;\n",
            "Prediction\n",
            "trrldng \n",
            "loss: 1.979999  [102464/123932]\n",
            "Input\n",
            "t of Mar\n",
            "Target\n",
            " of Mars\n",
            "Prediction\n",
            "htf tarn\n",
            "loss: 1.996174  [108864/123932]\n",
            "Input\n",
            "st have \n",
            "Target\n",
            "t have y\n",
            "Prediction\n",
            "  teve t\n",
            "loss: 2.105564  [115264/123932]\n",
            "Input\n",
            "IR STEPH\n",
            "Target\n",
            "R STEPHE\n",
            "Prediction\n",
            " GCOEREY\n",
            "loss: 1.991844  [121664/123932]\n",
            "Input\n",
            "here, dr\n",
            "Target\n",
            "ere, dri\n",
            "Prediction\n",
            "e e  tee\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.956216  [   64/123932]\n",
            "Input\n",
            "aring fe\n",
            "Target\n",
            "ring fea\n",
            "Prediction\n",
            "neng toa\n",
            "loss: 1.788441  [ 6464/123932]\n",
            "Input\n",
            " morn be\n",
            "Target\n",
            "morn bet\n",
            "Prediction\n",
            "tere te \n",
            "loss: 1.760482  [12864/123932]\n",
            "Input\n",
            ", as int\n",
            "Target\n",
            " as into\n",
            "Prediction\n",
            " an tt o\n",
            "loss: 1.944360  [19264/123932]\n",
            "Input\n",
            "doth res\n",
            "Target\n",
            "oth rese\n",
            "Prediction\n",
            " nheteas\n",
            "loss: 1.948456  [25664/123932]\n",
            "Input\n",
            "t were a\n",
            "Target\n",
            " were as\n",
            "Prediction\n",
            "htire tn\n",
            "loss: 1.880138  [32064/123932]\n",
            "Input\n",
            "vours\n",
            "Of\n",
            "Target\n",
            "ours\n",
            "Of \n",
            "Prediction\n",
            "eug eTf \n",
            "loss: 1.992722  [38464/123932]\n",
            "Input\n",
            "e awhile\n",
            "Target\n",
            " awhile,\n",
            "Prediction\n",
            " tna cd \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ee6bcdaeb415>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mrun_n_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-ee6bcdaeb415>\u001b[0m in \u001b[0;36mrun_n_epochs\u001b[0;34m(epochs, dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mrun_n_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-ee6bcdaeb415>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer, t)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx2char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         torch.save({\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_disable_byteorder_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0;31m# Now that it is on the CPU we can directly copy it into the zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0mnum_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m         \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"model_epoch9.pt\")"
      ],
      "metadata": {
        "id": "GYquG9OhwywG"
      },
      "id": "GYquG9OhwywG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint['model_state_dict'].keys()"
      ],
      "metadata": {
        "id": "Q-5QU4T61EIK",
        "outputId": "17113905-c73c-49bd-e4f2-886dae80ed96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Q-5QU4T61EIK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['norm.weight', 'norm.bias', 'embedding.embedding.weight', 'embedding.embedding.bias', 'multiheads1.0.WQs.0.weight', 'multiheads1.0.WQs.0.bias', 'multiheads1.0.WQs.1.weight', 'multiheads1.0.WQs.1.bias', 'multiheads1.0.WQs.2.weight', 'multiheads1.0.WQs.2.bias', 'multiheads1.0.WQs.3.weight', 'multiheads1.0.WQs.3.bias', 'multiheads1.0.WQs.4.weight', 'multiheads1.0.WQs.4.bias', 'multiheads1.0.WQs.5.weight', 'multiheads1.0.WQs.5.bias', 'multiheads1.0.WQs.6.weight', 'multiheads1.0.WQs.6.bias', 'multiheads1.0.WQs.7.weight', 'multiheads1.0.WQs.7.bias', 'multiheads1.0.WKs.0.weight', 'multiheads1.0.WKs.0.bias', 'multiheads1.0.WKs.1.weight', 'multiheads1.0.WKs.1.bias', 'multiheads1.0.WKs.2.weight', 'multiheads1.0.WKs.2.bias', 'multiheads1.0.WKs.3.weight', 'multiheads1.0.WKs.3.bias', 'multiheads1.0.WKs.4.weight', 'multiheads1.0.WKs.4.bias', 'multiheads1.0.WKs.5.weight', 'multiheads1.0.WKs.5.bias', 'multiheads1.0.WKs.6.weight', 'multiheads1.0.WKs.6.bias', 'multiheads1.0.WKs.7.weight', 'multiheads1.0.WKs.7.bias', 'multiheads1.0.WVs.0.weight', 'multiheads1.0.WVs.0.bias', 'multiheads1.0.WVs.1.weight', 'multiheads1.0.WVs.1.bias', 'multiheads1.0.WVs.2.weight', 'multiheads1.0.WVs.2.bias', 'multiheads1.0.WVs.3.weight', 'multiheads1.0.WVs.3.bias', 'multiheads1.0.WVs.4.weight', 'multiheads1.0.WVs.4.bias', 'multiheads1.0.WVs.5.weight', 'multiheads1.0.WVs.5.bias', 'multiheads1.0.WVs.6.weight', 'multiheads1.0.WVs.6.bias', 'multiheads1.0.WVs.7.weight', 'multiheads1.0.WVs.7.bias', 'multiheads2.0.WQs.0.weight', 'multiheads2.0.WQs.0.bias', 'multiheads2.0.WQs.1.weight', 'multiheads2.0.WQs.1.bias', 'multiheads2.0.WQs.2.weight', 'multiheads2.0.WQs.2.bias', 'multiheads2.0.WQs.3.weight', 'multiheads2.0.WQs.3.bias', 'multiheads2.0.WQs.4.weight', 'multiheads2.0.WQs.4.bias', 'multiheads2.0.WQs.5.weight', 'multiheads2.0.WQs.5.bias', 'multiheads2.0.WQs.6.weight', 'multiheads2.0.WQs.6.bias', 'multiheads2.0.WQs.7.weight', 'multiheads2.0.WQs.7.bias', 'multiheads2.0.WKs.0.weight', 'multiheads2.0.WKs.0.bias', 'multiheads2.0.WKs.1.weight', 'multiheads2.0.WKs.1.bias', 'multiheads2.0.WKs.2.weight', 'multiheads2.0.WKs.2.bias', 'multiheads2.0.WKs.3.weight', 'multiheads2.0.WKs.3.bias', 'multiheads2.0.WKs.4.weight', 'multiheads2.0.WKs.4.bias', 'multiheads2.0.WKs.5.weight', 'multiheads2.0.WKs.5.bias', 'multiheads2.0.WKs.6.weight', 'multiheads2.0.WKs.6.bias', 'multiheads2.0.WKs.7.weight', 'multiheads2.0.WKs.7.bias', 'multiheads2.0.WVs.0.weight', 'multiheads2.0.WVs.0.bias', 'multiheads2.0.WVs.1.weight', 'multiheads2.0.WVs.1.bias', 'multiheads2.0.WVs.2.weight', 'multiheads2.0.WVs.2.bias', 'multiheads2.0.WVs.3.weight', 'multiheads2.0.WVs.3.bias', 'multiheads2.0.WVs.4.weight', 'multiheads2.0.WVs.4.bias', 'multiheads2.0.WVs.5.weight', 'multiheads2.0.WVs.5.bias', 'multiheads2.0.WVs.6.weight', 'multiheads2.0.WVs.6.bias', 'multiheads2.0.WVs.7.weight', 'multiheads2.0.WVs.7.bias', 'feedforwards.0.0.weight', 'feedforwards.0.0.bias', 'feedforwards.0.2.weight', 'feedforwards.0.2.bias', 'toLogit.weight', 'toLogit.bias'])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mymodel = LonelyDecoder(model_parameters)\n",
        "mymodel.load_state_dict(checkpoint['model_state_dict'])\n",
        "myoptimizer = torch.optim.Adam(decoder.parameters(), lr=1e-2, betas=(0.9, 0.98))\n",
        "myoptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "print(f\"Loaded checkpoint at epoch {epoch} with loss {loss}\")\n",
        "\n",
        "def train_loop(dataloader, model, loss_fn, optimizer, t):\n",
        "    \"\"\"Train loop. Taken from pytorch tutorial.\"\"\"\n",
        "    size = len(dataloader.dataset)\n",
        "    # Set the model to training mode - important for batch\n",
        "    # normalization and dropout layers Unnecessary in this situation\n",
        "    # but added for best practices\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred.transpose(1,2)[:,:,-1], y[:,-1])\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        # Optimizer step\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * 64 + len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "            print(\"Input\")\n",
        "            print(''.join([idx2char[i] for i in torch.max(X[0], dim=1)[1].tolist()]))\n",
        "            print(\"Target\")\n",
        "            print(''.join([idx2char[i] for i in y[0]]))\n",
        "            print(\"Prediction\")\n",
        "            print(''.join([idx2char[i] for i in torch.max(pred[0], dim=1)[1].tolist()]))\n",
        "        torch.save({\n",
        "            'epoch': t+1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, f\"model_epoch{t}.pt\")\n",
        "print(\"Train loop\")\n",
        "def run_n_epochs(epochs, dataloader, model, loss_fn, optimizer):\n",
        "    for t in range(epochs):\n",
        "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "        train_loop(dataloader, model, loss_fn, optimizer, t)\n",
        "run_n_epochs(1, train_dataloader, mymodel, loss_fn, optimizer)"
      ],
      "metadata": {
        "id": "MTk8uLaRw7tA",
        "outputId": "80cd89fe-c29c-4859-bcf5-2e9670af8d55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 912
        }
      },
      "id": "MTk8uLaRw7tA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded checkpoint at epoch 10 with loss 0.08523036539554596\n",
            "Train loop\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.264168  [   64/21870]\n",
            "Input\n",
            " at me, make their pastime at my sorrow:\n",
            "They shou\n",
            "Target\n",
            "at me, make their pastime at my sorrow:\n",
            "They shoul\n",
            "Prediction\n",
            "at me, make their pastime at my soreow:\n",
            "They shous\n",
            "loss: 2.465627  [ 6464/21870]\n",
            "Input\n",
            "t want their remedies.\n",
            "Cousin, I am too young to b\n",
            "Target\n",
            " want their remedies.\n",
            "Cousin, I am too young to be\n",
            "Prediction\n",
            " want their remedies.\n",
            "Cousin, I am too young to be\n",
            "loss: 2.635937  [12864/21870]\n",
            "Input\n",
            "h to me to be at enmity;\n",
            "I hate it, and desire all\n",
            "Target\n",
            " to me to be at enmity;\n",
            "I hate it, and desire all \n",
            "Prediction\n",
            " to me to be at enmity;\n",
            "I hate it, and desire alle\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-99a323ce3c56>\u001b[0m in \u001b[0;36m<cell line: 47>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mrun_n_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmymodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-99a323ce3c56>\u001b[0m in \u001b[0;36mrun_n_epochs\u001b[0;34m(epochs, dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mrun_n_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmymodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-99a323ce3c56>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer, t)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Optimizer step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = next(iter(train_dataloader))\n",
        "print(x.shape)\n",
        "decoder.eval()\n",
        "print(''.join([idx2char[i] for i in torch.max(x[30], dim=1)[1].tolist()]))\n",
        "print(''.join([idx2char[i] for i in torch.max(decoder(x[30].squeeze(0))[0],1)[1].tolist()]))\n",
        "\n",
        "decoder.eval()\n",
        "totalString = \"HECTOR:\"\n",
        "for w in range(500):\n",
        "  input = [char2idx[c] for c in totalString[-8:]]\n",
        "  one_hot_initString = F.one_hot(torch.tensor(input).long(),\n",
        "                             model_parameters[\"vocabulary_size\"]).float()\n",
        "  next_char = torch.max(decoder(one_hot_initString.squeeze(0))[0],1)[1].tolist()[-1]\n",
        "  totalString = totalString + idx2char[next_char]\n",
        "\n",
        "print(one_hot_initString.shape)\n",
        "print(\"###\")\n",
        "print(totalString) #''.join([idx2char[i] for i in torch.max(decoder(one_hot_initString.squeeze(0))[0],1)[1].tolist()]))\n",
        "print(\"###\")"
      ],
      "metadata": {
        "id": "fXi_qqUdnmko",
        "outputId": "49636396-15ee-4b2a-a5b0-051f19058fe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "fXi_qqUdnmko",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 8, 67])\n",
            "\n",
            "May thi\n",
            "\n",
            "ar lhes\n",
            "torch.Size([8, 67])\n",
            "###\n",
            "HECTOR:\n",
            "The shall the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand the stand\n",
            "###\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = next(iter(train_dataloader))\n",
        "print(x.shape)\n",
        "decoder.eval()\n",
        "print(''.join([idx2char[i] for i in torch.max(x[30], dim=1)[1].tolist()]))\n",
        "print(''.join([idx2char[i] for i in torch.max(decoder(x[30].squeeze(0))[0],1)[1].tolist()]))\n",
        "\n",
        "decoder.eval()\n",
        "totalString = \"HECTOR:\"\n",
        "idxString = [char2idx[c] for c in totalString[-8:]]\n",
        "tokenizedString = F.one_hot(torch.tensor(idxString).long(),\n",
        "                             model_parameters[\"vocabulary_size\"]).float()\n",
        "\n",
        "print(tokenizedString.shape)\n",
        "for w in range(25):\n",
        "    #print(decoder(tokenizedString.squeeze(0))[0].shape)\n",
        "    next_char_proba = nn.Softmax(dim=-1)(decoder(tokenizedString.squeeze(0))[:,-1])\n",
        "    next_char = torch.max(decoder(tokenizedString.squeeze(0))[0],1)[1].tolist()[-1]\n",
        "    totalString = totalString + idx2char[next_char]\n",
        "    #print(f\"next_char_proba.shape {next_char_proba.shape}\")\n",
        "    #print(f\"tokenizedString.shape {tokenizedString.shape}\")\n",
        "    tokenizedString = torch.cat([tokenizedString[1:], next_char_proba], dim=0)\n",
        "    # print(tokenizedString)\n",
        "    #print(tokenizedString.shape)\n",
        "print(one_hot_initString.shape)\n",
        "print(\"###\")\n",
        "print(totalString) #''.join([idx2char[i] for i in torch.max(decoder(one_hot_initString.squeeze(0))[0],1)[1].tolist()]))\n",
        "print(\"###\")"
      ],
      "metadata": {
        "id": "zZjp_uFDr2qH",
        "outputId": "c513ae7a-9795-4c85-f499-6603df7c3149",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "zZjp_uFDr2qH",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 8, 67])\n",
            "vers, Va\n",
            "e y  aal\n",
            "torch.Size([7, 67])\n",
            "torch.Size([8, 67])\n",
            "###\n",
            "HECTOR:\n",
            "Tore eeel tenea elet ael\n",
            "###\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoder)"
      ],
      "metadata": {
        "id": "bzA5ndfgKu3O",
        "outputId": "2f12130e-25cf-446e-a87c-aeb9988df2a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bzA5ndfgKu3O",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LonelyDecoder(\n",
            "  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (embedding): Embedding(\n",
            "    (embedding): Linear(in_features=67, out_features=256, bias=True)\n",
            "  )\n",
            "  (multiheads1): ModuleList(\n",
            "    (0): MultiHeadAttention(\n",
            "      (WQs): ModuleList(\n",
            "        (0-7): 8 x Linear(in_features=256, out_features=32, bias=True)\n",
            "      )\n",
            "      (WKs): ModuleList(\n",
            "        (0-7): 8 x Linear(in_features=256, out_features=32, bias=True)\n",
            "      )\n",
            "      (WVs): ModuleList(\n",
            "        (0-7): 8 x Linear(in_features=256, out_features=32, bias=True)\n",
            "      )\n",
            "      (spda): ScaledDotProductAttention(\n",
            "        (softmax): Softmax(dim=None)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (multiheads2): ModuleList(\n",
            "    (0): MultiHeadAttention(\n",
            "      (WQs): ModuleList(\n",
            "        (0-7): 8 x Linear(in_features=256, out_features=32, bias=True)\n",
            "      )\n",
            "      (WKs): ModuleList(\n",
            "        (0-7): 8 x Linear(in_features=256, out_features=32, bias=True)\n",
            "      )\n",
            "      (WVs): ModuleList(\n",
            "        (0-7): 8 x Linear(in_features=256, out_features=32, bias=True)\n",
            "      )\n",
            "      (spda): ScaledDotProductAttention(\n",
            "        (softmax): Softmax(dim=None)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (feedforwards): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (toLogit): Linear(in_features=256, out_features=67, bias=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
        "x,y = next(iter(train_dataloader))\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "print(torch.max(x[0], dim=1)[1].tolist())\n",
        "print(y[0])"
      ],
      "metadata": {
        "id": "9tSdscqGACDC",
        "outputId": "e2db63e9-f08d-4c46-8831-dca34ce4643c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9tSdscqGACDC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 8, 67])\n",
            "torch.Size([64, 8])\n",
            "[20, 49, 58, 59, 60, 1, 17, 49]\n",
            "tensor([49, 58, 59, 60,  1, 17, 49, 60])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5a15921-6375-4b45-89ab-63391172ce28",
      "metadata": {
        "id": "f5a15921-6375-4b45-89ab-63391172ce28",
        "outputId": "ce2d8939-861a-46f0-8b26-071127d0886e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 4])\n",
            "tensor([[0., 0., 1., 0., 0.],\n",
            "        [0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1.]])\n",
            "tensor(0.9048)\n"
          ]
        }
      ],
      "source": [
        "# Example of target with class indices\n",
        "loss = nn.CrossEntropyLoss()\n",
        "target = torch.empty(3, dtype=torch.long).random_(5)\n",
        "input = F.one_hot(target, num_classes=5).float()\n",
        "print(target)\n",
        "print(input)\n",
        "output = loss(input, target)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_n_epochs(epochs, dataloader, model, loss_fn, optimizer):\n",
        "    for t in range(epochs):\n",
        "        print(f\"Epoch {5+t+1}\\n-------------------------------\")\n",
        "        train_loop(dataloader, model, loss_fn, optimizer)\n",
        "\n",
        "run_n_epochs(45, train_dataloader, decoder, loss_fn, optimizer)"
      ],
      "metadata": {
        "id": "TLq7ZWnHr104",
        "outputId": "98f9b8bb-56a2-44ae-9160-82b58e63a5db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "TLq7ZWnHr104",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 4.009966  [   64/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "XHakevm'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 3.983451  [ 6464/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "qZ mfjj,\n",
            "loss: 3.990031  [12864/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "obQQfQzZ\n",
            "loss: 4.036373  [19264/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "whWQooX \n",
            "loss: 4.001715  [25664/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "-gQGakn,\n",
            "loss: 4.010240  [32064/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "g,#.TTJy\n",
            "loss: 4.002563  [38464/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "o-r.merx\n",
            "loss: 4.007478  [44864/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "our\n",
            "Miou\n",
            "loss: 3.987219  [51264/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "asbib!bj\n",
            "loss: 4.015161  [57664/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "XuyxVkuc\n",
            "loss: 4.015061  [64064/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "yd,\n",
            "wiad\n",
            "loss: 4.015932  [70464/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "T&eqtqzt\n",
            "loss: 3.983913  [76864/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "\n",
            "Wha.Wr'\n",
            "loss: 4.002244  [83264/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "nd;-n-;P\n",
            "loss: 4.000215  [89664/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "';'Pjjzn\n",
            "loss: 4.019834  [96064/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "\n",
            "b;exQ;Q\n",
            "loss: 3.983692  [102464/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "q KavevH\n",
            "loss: 4.007519  [108864/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "q3ousJ;@\n",
            "loss: 4.042298  [115264/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            " t,3I Ih\n",
            "loss: 3.993047  [121664/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "i3-his$q\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 4.009781  [   64/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "'D'JI.f.\n",
            "loss: 4.008904  [ 6464/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "haoj3unc\n",
            "loss: 4.020438  [12864/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "rrQYyQro\n",
            "loss: 3.994052  [19264/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "33;iin z\n",
            "loss: 4.010096  [25664/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "jxjQjj-j\n",
            "loss: 3.965109  [32064/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "33myx c-\n",
            "loss: 3.986863  [38464/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "s'zTXs''\n",
            "loss: 3.987497  [44864/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "'Mh''Wj'\n",
            "loss: 3.996432  [51264/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "SJvX-@xZ\n",
            "loss: 4.019480  [57664/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "XQQrg&xn\n",
            "loss: 4.010562  [64064/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "Bikxq;bn\n",
            "loss: 4.002163  [70464/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "d3??tzt-\n",
            "loss: 3.961648  [76864/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "jxjz;bfJ\n",
            "loss: 3.993537  [83264/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            ".f'TfofJ\n",
            "loss: 3.964676  [89664/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "jsXqss:\n",
            "\n",
            "loss: 3.987367  [96064/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "!n3al!'J\n",
            "loss: 4.018489  [102464/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "bexTQ-?r\n",
            "loss: 3.991456  [108864/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "PrH FFrJ\n",
            "loss: 4.018596  [115264/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "!wJQzo! \n",
            "loss: 4.004164  [121664/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "ZxxZdZpr\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 3.998062  [   64/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "3KikkQkk\n",
            "loss: 4.010931  [ 6464/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "q3h&goug\n",
            "loss: 3.999441  [12864/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "uX!uzO:l\n",
            "loss: 3.995297  [19264/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            ".zzzzzz.\n",
            "loss: 3.964694  [25664/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "ankakBin\n",
            "loss: 4.009676  [32064/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "i:wizh3w\n",
            "loss: 3.977067  [38464/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "ikkk! ki\n",
            "loss: 3.997163  [44864/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "zmyZWiZt\n",
            "loss: 3.982253  [51264/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "OPLT'OY:\n",
            "loss: 3.984232  [57664/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "-.gj3-g3\n",
            "loss: 4.019158  [64064/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            ":&ffoD?n\n",
            "loss: 3.983885  [70464/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "J3ul!!Zd\n",
            "loss: 3.981462  [76864/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "k?qcc?c.\n",
            "loss: 4.005831  [83264/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "wiz!iu?-\n",
            "loss: 3.984880  [89664/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "mvev;eqv\n",
            "loss: 3.976781  [96064/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "emmk m,k\n",
            "loss: 4.008554  [102464/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "bppXpk, \n",
            "loss: 3.977186  [108864/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "XttXt!?w\n",
            "loss: 3.971331  [115264/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "\n",
            "CAARCHC\n",
            "loss: 3.974417  [121664/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "v?,X!vz!\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 3.993505  [   64/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "j'Poxz3c\n",
            "loss: 3.992613  [ 6464/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "Ubjavxav\n",
            "loss: 4.007241  [12864/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "thq3itt?\n",
            "loss: 4.004530  [19264/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "-bb?bzZb\n",
            "loss: 3.995043  [25664/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "i qsqisi\n",
            "loss: 4.002447  [32064/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "I:ICVI\n",
            "I\n",
            "loss: 3.974081  [38464/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "3cqck3cl\n",
            "loss: 3.973033  [44864/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "ET\n",
            "Why,\n",
            "\n",
            "loss: 3.994256  [51264/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "qD33Q3ex\n",
            "loss: 3.968574  [57664/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "Hbbzzz;M\n",
            "loss: 4.008118  [64064/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "?cq??x?\n",
            "\n",
            "loss: 3.995346  [70464/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "xss;s:Z@\n",
            "loss: 3.988353  [76864/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "ZqbyqPeq\n",
            "loss: 3.990261  [83264/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "pcXpVXWh\n",
            "loss: 3.999664  [89664/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "JQv!x$rq\n",
            "loss: 3.981891  [96064/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "xvJuofuZ\n",
            "loss: 3.998492  [102464/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "j;zbhexK\n",
            "loss: 4.008811  [108864/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "-zirQZ!W\n",
            "loss: 4.020496  [115264/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "l??J??-W\n",
            "loss: 3.970493  [121664/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "l3q!avll\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 3.997797  [   64/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "GRCDCHAG\n",
            "loss: 3.980371  [ 6464/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "r-ZGufZJ\n",
            "loss: 4.005164  [12864/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "OOLXL:qw\n",
            "loss: 3.998323  [19264/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            ",xQ, c,;\n",
            "loss: 3.976596  [25664/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "vvvDUsev\n",
            "loss: 3.989638  [32064/123932]\n",
            "Target\n",
            "irst Cit\n",
            "Prediction\n",
            "HxYousyZ\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-291c39be0d3b>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrun_n_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-66-291c39be0d3b>\u001b[0m in \u001b[0;36mrun_n_epochs\u001b[0;34m(epochs, dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {5+t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mrun_n_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-65-38241210b6fc>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W51VPcfq2V76"
      },
      "id": "W51VPcfq2V76",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}