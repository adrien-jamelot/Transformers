{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamadri/Transformers/blob/main/model_utils_and_training_drive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f49b63e5-0c97-470b-817e-0f82f14dfd8d",
      "metadata": {
        "id": "f49b63e5-0c97-470b-817e-0f82f14dfd8d"
      },
      "source": [
        "# Utils and Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a72566f-8da4-40a0-851d-54fe28fb7636",
      "metadata": {
        "id": "6a72566f-8da4-40a0-851d-54fe28fb7636"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03bcd3cb-50f6-4a83-9113-15a6f1f2ba28",
      "metadata": {
        "id": "03bcd3cb-50f6-4a83-9113-15a6f1f2ba28"
      },
      "source": [
        "### addAndNorm.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "df6ea7fd-ec7d-4c37-b5e8-73e663b1ec30",
      "metadata": {
        "id": "df6ea7fd-ec7d-4c37-b5e8-73e663b1ec30"
      },
      "outputs": [],
      "source": [
        "\"\"\"Residual connection.\"\"\"\n",
        "\n",
        "\n",
        "def addAndNorm(x, blockOutput, norm):\n",
        "    \"\"\"Residual connection.\"\"\"\n",
        "    return norm(x + blockOutput)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6176556f-9240-493a-93d9-8f3a0c9b42ef",
      "metadata": {
        "id": "6176556f-9240-493a-93d9-8f3a0c9b42ef"
      },
      "source": [
        "### PositionalEncoding.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d9923029-9788-4ce9-8518-2b21105d3929",
      "metadata": {
        "id": "d9923029-9788-4ce9-8518-2b21105d3929"
      },
      "outputs": [],
      "source": [
        "\"\"\"Positional Encoding.\"\"\"\n",
        "import math\n",
        "import torch\n",
        "\n",
        "\n",
        "def positionalEncoding(x, dim_model):\n",
        "    \"\"\"Positional Encoding.\"\"\"\n",
        "    def sineOrCosine(i):\n",
        "        \"\"\"sin(alpha+pi/2) = cos(alpha).\"\"\"\n",
        "        return math.pi/2*(i % 2 == 1)\n",
        "    values = [\n",
        "        [sineOrCosine(i) + pos/math.pow(10000, 2*(i//2)/dim_model) for\n",
        "         i in range(dim_model)]\n",
        "        for pos in range(x.shape[0])\n",
        "    ]\n",
        "    return torch.sin(torch.tensor(values))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1106be76-87e9-405c-a431-8569ef02043a",
      "metadata": {
        "id": "1106be76-87e9-405c-a431-8569ef02043a"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "9297b179-d38c-4cb9-a023-4f32a6d26367",
      "metadata": {
        "id": "9297b179-d38c-4cb9-a023-4f32a6d26367"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    \"\"\"Main transformer block.\n",
        "\n",
        "    Inputs: - model_parameters: ordered dictionary of key-values describing the\n",
        "    layer parameters of the model:\n",
        "      - dim_model: dimension of the model.\n",
        "      - layers: dictionary of key-values describing specific layers\n",
        "        - <layer_name>: dictionary of parameters for the specific multi-head\n",
        "          layer\n",
        "          - attention: dictionary of parameters for the specific attention\n",
        "            function\n",
        "            - dim_key: dimension of the key and query.\n",
        "            - dim_value: dimension of the value.\n",
        "          - nb_head: number of heads.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_parameters):\n",
        "        \"\"\"Initialize parameters.\"\"\"\n",
        "        super().__init__()\n",
        "        self.dim_model = model_parameters[\"dim_model\"]\n",
        "        self.encoder = Encoder(model_parameters[\"encoder\"])\n",
        "        self.decoder = Decoder(model_parameters[\"decoder\"])\n",
        "        self.embedding = Embedding(model_parameters)\n",
        "        self.toProba = nn.Sequential(\n",
        "            nn.Linear(self.dim_model,\n",
        "                      model_parameters[\"vocabulary_size\"]),\n",
        "            nn.Softmax()\n",
        "        )\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x, lastOutput):\n",
        "        \"\"\"Apply a step forward.\"\"\"\n",
        "        encoderInput = self.embedding(x) + positionalEncoding(\n",
        "            x, self.dim_model)\n",
        "        decoderInput = self.embedding(lastOutput) + positionalEncoding(\n",
        "            lastOutput, self.dim_model)\n",
        "        encoderInput = self.dropout(encoderInput)\n",
        "        decoderInput = self.dropout(decoderInput)\n",
        "        encoderOutput = self.encoder(encoderInput)\n",
        "        decoderOutput = self.decoder(decoderInput, encoderOutput)\n",
        "        lastOutput = self.toProba(decoderOutput)\n",
        "        return lastOutput\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"Encoder.\"\"\"\n",
        "\n",
        "    def __init__(self, encoderConfig):\n",
        "        \"\"\"Initialize.\"\"\"\n",
        "        super().__init__()\n",
        "        self.nb_layers = encoderConfig[\"nb_layers\"]\n",
        "        self.dim_model = encoderConfig[\"dim_model\"]\n",
        "        self.dim_feedforward = encoderConfig[\"feedforward\"][\"dim_feedforward\"]\n",
        "        self.norm = nn.LayerNorm(normalized_shape=self.dim_model,\n",
        "                                 elementwise_affine=True, bias=True)\n",
        "        self.multiheads = [MultiHeadAttention(encoderConfig[\"multihead\"],\n",
        "                                              masked=False)\n",
        "                           for i in range(self.nb_layers)]\n",
        "        self.feedforwards = [nn.Sequential(nn.Linear(self.dim_model,\n",
        "                                                     self.dim_feedforward),\n",
        "                                           nn.ReLU(),\n",
        "                                           nn.Linear(self.dim_feedforward,\n",
        "                                                     self.dim_model))\n",
        "                             for i in range(self.nb_layers)]\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward.\"\"\"\n",
        "        for i in range(self.nb_layers):\n",
        "            h1 = addAndNorm(x, self.dropout(self.multiheads[i](x, x,\n",
        "                                                               x)),\n",
        "                            self.norm)\n",
        "            x = addAndNorm(h1, self.dropout(self.feedforwards[i](h1)),\n",
        "                           self.norm)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"Decoder.\"\"\"\n",
        "\n",
        "    def __init__(self, decoderConfig):\n",
        "        \"\"\"Initialize.\"\"\"\n",
        "        super().__init__()\n",
        "        self.dim_model = decoderConfig[\"dim_model\"]\n",
        "        self.norm = nn.LayerNorm(normalized_shape=self.dim_model)\n",
        "        self.dim_feedforward = decoderConfig[\"feedforward\"][\"dim_feedforward\"]\n",
        "        self.nb_layers = decoderConfig[\"nb_layers\"]\n",
        "        self.layer = []\n",
        "        self.multiheads1 = [MultiHeadAttention(decoderConfig[\"multihead\"],\n",
        "                                               masked=True)\n",
        "                            for i in range(self.nb_layers)]\n",
        "        self.multiheads2 = [MultiHeadAttention(decoderConfig[\"multihead\"],\n",
        "                                               masked=False)\n",
        "                            for i in range(self.nb_layers)]\n",
        "        self.feedforwards = [nn.Sequential(nn.Linear(self.dim_model,\n",
        "                                                     self.dim_feedforward),\n",
        "                                           nn.ReLU(),\n",
        "                                           nn.Linear(self.dim_feedforward,\n",
        "                                                     self.dim_model))\n",
        "                             for i in range(self.nb_layers)]\n",
        "\n",
        "    def forward(self, decoderInput, encoderOutput):\n",
        "        \"\"\"Forward.\"\"\"\n",
        "        for i in range(self.nb_layers):\n",
        "            h1 = addAndNorm(decoderInput,\n",
        "                            self.multiheads1[i](decoderInput,\n",
        "                                                decoderInput,\n",
        "                                                decoderInput),\n",
        "                            self.norm)\n",
        "            h2 = addAndNorm(h1,\n",
        "                            self.multiheads2[i](h1,\n",
        "                                                encoderOutput,\n",
        "                                                encoderOutput),\n",
        "                            self.norm)\n",
        "            lastOutput = addAndNorm(h2,\n",
        "                                    self.feedforwards[i](h2),\n",
        "                                    self.norm)\n",
        "        return lastOutput\n",
        "\n",
        "\n",
        "class LonelyDecoder(nn.Module):\n",
        "    \"\"\"A lonely decoder.\"\"\"\n",
        "\n",
        "    def __init__(self, model_parameters):\n",
        "        \"\"\"Initialize.\"\"\"\n",
        "        super().__init__()\n",
        "        self.decoderConfig = model_parameters[\"decoder\"]\n",
        "        self.dim_model = self.decoderConfig[\"dim_model\"]\n",
        "        self.norm = nn.LayerNorm(normalized_shape=self.dim_model)\n",
        "        self.dim_feedforward = self.decoderConfig[\"feedforward\"][\"dim_feedforward\"]\n",
        "        self.nb_layers = self.decoderConfig[\"nb_layers\"]\n",
        "        self.layer = []\n",
        "        self.embedding = Embedding(model_parameters)\n",
        "        self.multiheads1 = [MultiHeadAttention(self.decoderConfig[\"multihead\"],\n",
        "                                               masked=True)\n",
        "                            for i in range(self.nb_layers)]\n",
        "        self.multiheads2 = [MultiHeadAttention(self.decoderConfig[\"multihead\"],\n",
        "                                               masked=False)\n",
        "                            for i in range(self.nb_layers)]\n",
        "        self.feedforwards = [nn.Sequential(nn.Linear(self.dim_model,\n",
        "                                                     self.dim_feedforward),\n",
        "                                           nn.ReLU(),\n",
        "                                           nn.Linear(self.dim_feedforward,\n",
        "                                                     self.dim_model))\n",
        "                             for i in range(self.nb_layers)]\n",
        "        self.toProba = nn.Sequential(\n",
        "            nn.Linear(self.dim_model,\n",
        "                      model_parameters[\"vocabulary_size\"]),\n",
        "            nn.Softmax()\n",
        "        )\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward.\"\"\"\n",
        "        x = self.embedding(x) + positionalEncoding(\n",
        "            x, self.dim_model)\n",
        "        for i in range(self.nb_layers):\n",
        "            h1 = addAndNorm(x,\n",
        "                            self.multiheads1[i](x, x, x),\n",
        "                            self.norm)\n",
        "            h2 = addAndNorm(h1,\n",
        "                            self.multiheads2[i](h1, h1, h1),\n",
        "                            self.norm)\n",
        "            layerOutput = addAndNorm(h2,\n",
        "                                     self.feedforwards[i](h2),\n",
        "                                     self.norm)\n",
        "        finalOutput = self.toProba(layerOutput)\n",
        "        return finalOutput\n",
        "\n",
        "\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    \"\"\"Scaled Dot-Product Attention.\"\"\"\n",
        "\n",
        "    def __init__(self, dim_model, masked=False):\n",
        "        \"\"\"Initialize.\n",
        "\n",
        "        Inputs:\n",
        "        - dim_model: model dimension\n",
        "        - masked: prevents tokens to attend to the following ones.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.dim_model = dim_model\n",
        "        self.masked = masked\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, Q, K, V):\n",
        "        \"\"\"Forward.\n",
        "\n",
        "        Inputs:\n",
        "        - Q: query\n",
        "        - K: key\n",
        "        - V: value\n",
        "        \"\"\"\n",
        "        matmul_0 = torch.matmul(Q, K.transpose(0, 1))\n",
        "        scaled = torch.divide(matmul_0, torch.Tensor([self.dim_model]))\n",
        "        if self.masked:\n",
        "            mask = torch.ones(scaled.shape)\n",
        "            mask = mask - torch.tril(mask)*mask\n",
        "            mask = torch.where(mask == 1, float('-inf'), 0)\n",
        "            scaled = scaled + mask\n",
        "        softmaxed = self.softmax(scaled)\n",
        "        sdpa = torch.matmul(softmaxed, V)\n",
        "        return sdpa\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"Multi-Head Attention.\n",
        "\n",
        "    Inputs:\n",
        "    - multi_head_config: dictionary\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, multi_head_config, masked=False):\n",
        "        \"\"\"Initialize multi-head.\"\"\"\n",
        "        super().__init__()\n",
        "        self.dim_key = multi_head_config[\"attention\"][\"dim_key\"]\n",
        "        self.dim_value = multi_head_config[\"attention\"][\"dim_value\"]\n",
        "        self.nb_heads = multi_head_config[\"nb_heads\"]\n",
        "        self.dim_model = self.dim_key * self.nb_heads\n",
        "\n",
        "        self.WQs = [nn.Linear(self.dim_model, self.dim_key)\n",
        "                    for i in range(self.nb_heads)]\n",
        "        self.WKs = [nn.Linear(self.dim_model, self.dim_key)\n",
        "                    for i in range(self.nb_heads)]\n",
        "        self.WVs = [nn.Linear(self.dim_model, self.dim_value)\n",
        "                    for i in range(self.nb_heads)]\n",
        "        self.spda = ScaledDotProductAttention(self.dim_model, masked)\n",
        "\n",
        "    def forward(self, Q, K, V):\n",
        "        \"\"\"One step of the multi-head block.\"\"\"\n",
        "        heads = [self.spda(self.WQs[i](Q),\n",
        "                           self.WKs[i](K),\n",
        "                           self.WVs[i](V))\n",
        "                 for i in range(self.nb_heads)]\n",
        "        return torch.cat([head for head in heads], 1)\n",
        "\n",
        "\n",
        "class Embedding(nn.Module):\n",
        "    \"\"\"Embedding.\"\"\"\n",
        "\n",
        "    def __init__(self, model_parameters):\n",
        "        \"\"\"Initialize embedding.\"\"\"\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Linear(model_parameters[\"vocabulary_size\"],\n",
        "                                   model_parameters[\"dim_model\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward step.\"\"\"\n",
        "        return self.embedding(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39d82e56-e9f2-4551-9461-6a16c6824a42",
      "metadata": {
        "id": "39d82e56-e9f2-4551-9461-6a16c6824a42"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "with open('/content/drive/My Drive/foo.txt', 'w') as f:\n",
        "  f.write('Hello Google Drive!')\n",
        "!cat /content/drive/My\\ Drive/foo.txt"
      ],
      "metadata": {
        "id": "WlgZBE6f5jIb",
        "outputId": "89680125-f0fb-435a-a85e-0b5976f0405a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "WlgZBE6f5jIb",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/Transformers/data"
      ],
      "metadata": {
        "id": "i9_mRnQ766eo",
        "outputId": "cc2e3dec-3fd8-4414-80f7-752566c44aaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "i9_mRnQ766eo",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiny_shakespeare.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "199362f1-377e-4955-86c2-f775b520b012",
      "metadata": {
        "id": "199362f1-377e-4955-86c2-f775b520b012"
      },
      "outputs": [],
      "source": [
        "tiny_shakespeare = open('/content/drive/MyDrive/Transformers/data/tiny_shakespeare.txt',\n",
        "            'rb').read().decode(encoding='utf-8')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ab4af4e-d6f7-4380-b6dd-bc270c76644d",
      "metadata": {
        "id": "2ab4af4e-d6f7-4380-b6dd-bc270c76644d"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "1ae36615-9abe-48c3-851b-e1d88cc4ed79",
      "metadata": {
        "id": "1ae36615-9abe-48c3-851b-e1d88cc4ed79",
        "outputId": "277872e0-1413-4f6c-d148-06321c69962d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "67 unique characters\n",
            "char2idx\n",
            "{'\\n': 0, ' ': 1, '!': 2, '#': 3, '$': 4, '&': 5, \"'\": 6, ',': 7, '-': 8, '.': 9, '3': 10, ':': 11, ';': 12, '?': 13, '@': 14, 'A': 15, 'B': 16, 'C': 17, 'D': 18, 'E': 19, 'F': 20, 'G': 21, 'H': 22, 'I': 23, 'J': 24, 'K': 25, 'L': 26, 'M': 27, 'N': 28, 'O': 29, 'P': 30, 'Q': 31, 'R': 32, 'S': 33, 'T': 34, 'U': 35, 'V': 36, 'W': 37, 'X': 38, 'Y': 39, 'Z': 40, 'a': 41, 'b': 42, 'c': 43, 'd': 44, 'e': 45, 'f': 46, 'g': 47, 'h': 48, 'i': 49, 'j': 50, 'k': 51, 'l': 52, 'm': 53, 'n': 54, 'o': 55, 'p': 56, 'q': 57, 'r': 58, 's': 59, 't': 60, 'u': 61, 'v': 62, 'w': 63, 'x': 64, 'y': 65, 'z': 66}\n",
            "idx2char\n",
            "['\\n' ' ' '!' '#' '$' '&' \"'\" ',' '-' '.' '3' ':' ';' '?' '@' 'A' 'B' 'C'\n",
            " 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U'\n",
            " 'V' 'W' 'X' 'Y' 'Z' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm'\n",
            " 'n' 'o' 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n",
            "text_as_int\n",
            "[20 49 58 ... 47  9  0]\n",
            "'First Citizen' ---- characters mapped to int ---- >[20 49 58 59 60  1 17 49 60 49 66 45 54]\n",
            "tensor([20, 49, 58,  ..., 47,  9,  0])\n",
            "There are 123933 chunks of 8 characters available for the\n",
            "network training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: torch.Size([64, 8, 67])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (8) must match the size of tensor b (64) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-096dee07d826>\u001b[0m in \u001b[0;36m<cell line: 153>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m                                                           1)[1].tolist()]))\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-096dee07d826>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# Compute prediction and loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"X shape: {X.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchar2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"@\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         pred = F.one_hot(torch.Tensor([pred]).long(),\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-d9cb4dff5f3d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;34m\"\"\"Forward.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         x = self.embedding(x) + positionalEncoding(\n\u001b[0m\u001b[1;32m    160\u001b[0m             x, self.dim_model)\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (8) must match the size of tensor b (64) at non-singleton dimension 1"
          ]
        }
      ],
      "source": [
        "# \"\"\"Training.\"\"\"\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "# # import Transformers.model.transformer.Transformer\n",
        "\n",
        "text = tiny_shakespeare\n",
        "print('Length of text: {} characters'.format(len(text)))\n",
        "print(text[:250])\n",
        "\n",
        "# unique characters in the file\n",
        "vocab = sorted(set(text+\"@\"+\"#\")) # @ will be the initial character\n",
        "                                  # and # the final character. They\n",
        "                                  # are not in the text.\n",
        "print('{} unique characters'.format(len(vocab)))\n",
        "\n",
        "# Lookup tables\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])\n",
        "print(\"char2idx\")\n",
        "print(char2idx)\n",
        "print(\"idx2char\")\n",
        "print(idx2char)\n",
        "print(\"text_as_int\")\n",
        "print(text_as_int)\n",
        "print ('{} ---- characters mapped to int ---- >{}'.format(repr(text[:13]), text_as_int[:13]))\n",
        "\n",
        "# Create training examples:\n",
        "seq_length = 8\n",
        "examples_per_epoch = len(text)//(seq_length)\n",
        "\n",
        "int_text_tensor = torch.tensor(text_as_int)\n",
        "chunks = torch.chunk(int_text_tensor, examples_per_epoch, 0)\n",
        "print(int_text_tensor)\n",
        "\n",
        "examples = [chunk[:-1] for chunk in chunks]\n",
        "targets = [chunk[1:] for chunk in chunks]\n",
        "print(f\"\"\"There are {len(examples)} chunks of {seq_length} characters available for the\n",
        "network training.\"\"\")\n",
        "\n",
        "\n",
        "\n",
        "model_parameters = {\n",
        "    \"dim_model\": 256,\n",
        "    \"vocabulary_size\": 67,\n",
        "    \"batch_size\": 64,\n",
        "    \"encoder\": {\n",
        "        \"nb_layers\": 1,\n",
        "        \"dim_model\": 256,\n",
        "        \"multihead\": {\n",
        "            \"attention\": {\n",
        "                \"dim_model\": 256,\n",
        "                \"dim_key\": 128,\n",
        "                \"dim_value\": 128\n",
        "                },\n",
        "            \"nb_heads\": 2\n",
        "            },\n",
        "        \"feedforward\": {\n",
        "            \"dim_feedforward\": 256\n",
        "            }\n",
        "        },\n",
        "    \"decoder\": {\n",
        "        \"nb_layers\": 1,\n",
        "        \"vocabulary_size\": 67,\n",
        "        \"dim_model\": 256,\n",
        "        \"multihead\": {\n",
        "            \"attention\": {\n",
        "                \"dim_model\": 256,\n",
        "                \"dim_key\": 128,\n",
        "                \"dim_value\": 128,\n",
        "            },\n",
        "            \"nb_heads\": 2\n",
        "        },\n",
        "        \"feedforward\": {\n",
        "            \"dim_feedforward\": 256\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# transformer = Transformer(model_parameters)\n",
        "# x = torch.randn(10, 128)\n",
        "# lastOutput = torch.randn(3, 128)\n",
        "# transformer(x, lastOutput)\n",
        "\n",
        "decoder = LonelyDecoder(model_parameters)\n",
        "x = torch.randn(10, model_parameters[\"vocabulary_size\"])\n",
        "lastOutput = torch.randn(3, model_parameters[\"vocabulary_size\"])\n",
        "decoder(x)\n",
        "\n",
        "\n",
        "one_hot_examples = F.one_hot(torch.stack(examples[:-1]).long(),\n",
        "                             model_parameters[\"vocabulary_size\"]).float()\n",
        "one_hot_targets = F.one_hot(torch.stack(targets[:-1]).long(), model_parameters[\"vocabulary_size\"]).float()\n",
        "\n",
        "decoder(one_hot_examples[0])\n",
        "one_hot_examples[0]\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "loss = loss_fn(decoder(one_hot_examples[0]), one_hot_targets[0])\n",
        "loss.backward()\n",
        "optimizer = torch.optim.Adam(decoder.parameters())\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "data = torch.stack((one_hot_examples, one_hot_targets), dim=0)\n",
        "class customDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data  = data\n",
        "    def __len__(self):\n",
        "        return data.shape[1]\n",
        "    def __getitem__(self, idx):\n",
        "        return data[0,idx], data[1, idx]\n",
        "\n",
        "dataset = customDataset(data)\n",
        "\n",
        "train_dataloader = DataLoader(customDataset(data[:,0:201]), batch_size=64, shuffle=True)\n",
        "\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    \"\"\"Train loop. Taken from pytorch tutorial.\"\"\"\n",
        "    size = len(dataloader.dataset)\n",
        "    # Set the model to training mode - important for batch\n",
        "    # normalization and dropout layers Unnecessary in this situation\n",
        "    # but added for best practices\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        print(f\"X shape: {X.shape}\")\n",
        "        pred = model(X)\n",
        "        pred = char2idx[\"@\"]\n",
        "        pred = F.one_hot(torch.Tensor([pred]).long(),\n",
        "                         model_parameters[\"vocabulary_size\"]).float()\n",
        "        for i in range(seq_length):\n",
        "            new_pred = model(pred)\n",
        "            print(new_pred.shape)\n",
        "            pred = torch.cat((pred, torch.unsqueeze(new_pred[-1], dim=0)))\n",
        "        print(pred.shape)\n",
        "        loss = loss_fn(torch.unsqueeze(pred[1:],0), y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch + len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "            print(''.join([idx2char[i] for i in torch.max(pred[1:],\n",
        "                                                          1)[1].tolist()]))\n",
        "\n",
        "train_loop(train_dataloader, decoder, loss_fn, optimizer)\n",
        "\n",
        "\n",
        "\n",
        "# device = (\n",
        "#     \"cuda\"\n",
        "#     if torch.cuda.is_available()\n",
        "#     else \"mps\"\n",
        "#     if torch.backends.mps.is_available()\n",
        "#     else \"cpu\"\n",
        "# )\n",
        "# print(f\"Using {device} device\")\n",
        "# #print(transformer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5a15921-6375-4b45-89ab-63391172ce28",
      "metadata": {
        "id": "f5a15921-6375-4b45-89ab-63391172ce28"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}